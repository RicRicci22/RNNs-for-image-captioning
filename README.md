# RNNs For Remote Sensing Image Captioning

This repo contains code to train and test different RNNs architecture on the remote sensing image captioning task. 

The networks have been trained on the UCM dataset [http://weegee.vision.ucmerced.edu/datasets/landuse.html]. 

The implementation uses Pytorch as deep learning library. 

It is a very "homemade" code, so it can as well contains conceptual or implementation errors, so please be careful when using it, and open issues for everything is not clear or that can be improved. I would really appreciate feedbacks, since I am trying as well to learn something in the NLP vast universe.

Since the dataset and weights are very heavy, they are not included in the repo. You can download them from the following links:

ucm_dataset -> https://drive.google.com/file/d/1xvPy-Ayr9XSml7T0sIJfWbQYX-j3pDQb/view?usp=sharing (download "ucm_dataset.zip", extract it and put it in the main folder)

weights -> https://drive.google.com/file/d/1AIsgF3xjvRPpXjQJNrO7a6SzWQGRTQa0/view?usp=sharing (download "weights.zip", extract it and put it in the main folder)

### TRAIN THE MODEL ON THE DATASET
### RUN INFERENCE ON THE FULL DATASET

### RUN INFERENCE ON A SINGLE IMAGE

### TODO
- [ ] Add the guide to train the model on the dataset
- [ ] Add the guide to run inference on the full dataset
- [ ] Add the guide to run inference on a single image
- [ ] Improve readme appearence
