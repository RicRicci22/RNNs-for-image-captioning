# RNNs-for-image-captioning

This repo contains code to train and test different RNNs architecture on the remote sensing image captioning task. 

The networks have been trained on the UCM dataset [http://weegee.vision.ucmerced.edu/datasets/landuse.html]. 

The implementation uses Pytorch as deep learning library. 

It is a very "homemade" code, so it can as well contains conceptual or implementation errors, so please be careful when using it, and open issues for everything is not clear or that can be improved. I would really appreciate feedbacks, since I am trying as well to learn something in the NLP vast universe.

Since the dataset and weights are very heavy, they are not included in the repo. You can download them from the following links:

ucm_dataset -> https://drive.google.com/drive/folders/1Dck-pXpVilhYPmEteYSId0aB734_YaTs?usp=sharing (just download it, extract and put in the main folder)

weights -> 

# TRAIN THE MODEL ON THE DATASET
# RUN INFERENCE ON THE FULL DATASET

# RUN INFERENCE ON A SINGLE IMAGE


